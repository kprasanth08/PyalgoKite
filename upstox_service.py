import re

import upstox_client
from upstox_client.api import LoginApi, MarketQuoteApi, MarketQuoteV3Api, HistoryV3Api, WebsocketApi  # Added WebsocketApi
from upstox_client.rest import ApiException
from upstox_client.configuration import Configuration

import json
import logging
import os
import time
from datetime import datetime, timedelta
from dotenv import load_dotenv
from token_manager import token_manager  # Import the token_manager singleton

# Add CSV handling imports
import csv
import requests
import gzip  # Add gzip module for handling compressed files
from io import StringIO, BytesIO  # Add BytesIO for binary data handling
import pandas as pd

# Configure logger first
logger = logging.getLogger(__name__)

# For WebSocket client
import asyncio
import websockets
import threading # Added for threading.Event

# Attempt to import the generated Protobuf file
# This file should be generated by you using protoc (see instructions)
# Use a global variable to track if we've already loaded the proto descriptor
_PROTOBUF_LOADED = False

try:
    # Only try to load the protobuf descriptors once
    if not _PROTOBUF_LOADED:
        import MarketDataFeed_pb2  # Assumes MarketDataFeed_pb2.py is in the same directory or Python path
        _PROTOBUF_LOADED = True
    else:
        import importlib
        MarketDataFeed_pb2 = importlib.import_module('MarketDataFeed_pb2')
except ImportError:
    logger.error("MarketDataFeed_pb2.py not found. Please generate it from the .proto file.")
    MarketDataFeed_pb2 = None

load_dotenv()

# Upstox API Configuration
UPSTOX_API_KEY = os.getenv('UPSTOX_API_KEY')
UPSTOX_API_SECRET = os.getenv('UPSTOX_API_SECRET')
UPSTOX_REDIRECT_URI = os.getenv('UPSTOX_REDIRECT_URI', 'http://localhost:6010/upstox_callback')

# NSE CSV file URLs and local storage paths
NSE_CSV_URL = "https://assets.upstox.com/market-quote/instruments/exchange/NSE.csv.gz"
NSE_CSV_LOCAL_PATH = os.path.join(os.path.dirname(os.path.abspath(__file__)), "instrument_cache", "nse_instruments.csv")
NSE_CSV_PROCESSED_PATH = os.path.join(os.path.dirname(os.path.abspath(__file__)), "instrument_cache", "nse_instruments_processed.json")

# Global cache for instruments
_instruments_cache = {
    "NSE_EQ": None,
    "BSE_EQ": None,
    "NSE_FO": None,
    "last_updated": None
}

def refresh_and_filter_nse_instruments():
    """
    Downloads, filters (for NSE_EQ), and saves NSE instruments to the cache file.
    Updates the in-memory cache as well.
    """
    try:
        logger.info(f"Attempting to download instruments from {NSE_CSV_URL}")
        response = requests.get(NSE_CSV_URL, stream=True)
        response.raise_for_status() # Raises an HTTPError for bad responses (4XX or 5XX)

        logger.info("Decompressing and reading CSV data...")
        # Use BytesIO to handle the binary content in memory for gzip
        with gzip.GzipFile(fileobj=BytesIO(response.content)) as gz_file:
            # Read the decompressed content as text (assuming UTF-8 encoding)
            csv_content = gz_file.read().decode('utf-8')
            # Use StringIO to treat the string as a file for csv.DictReader
            csv_file = StringIO(csv_content)
            reader = csv.DictReader(csv_file)
            all_instruments = list(reader)

        logger.info(f"Downloaded {len(all_instruments)} instruments. Filtering for exchange='NSE_EQ'...")

        nse_eq_instruments = []
        for instrument in all_instruments:
            # Assuming the CSV has an 'exchange' column and its value can be 'NSE_EQ'.
            # Adjust this condition if the CSV structure is different
            # (e.g., if exchange is 'NSE' and another column like 'instrument_type' is 'EQ').
            if instrument.get('exchange') == 'NSE_EQ':
                nse_eq_instruments.append(instrument)

        logger.info(f"Found {len(nse_eq_instruments)} NSE_EQ instruments after filtering.")

        # Ensure the cache directory exists
        cache_dir = os.path.dirname(NSE_CSV_PROCESSED_PATH)
        if not os.path.exists(cache_dir):
            os.makedirs(cache_dir)
            logger.info(f"Created cache directory: {cache_dir}")

        with open(NSE_CSV_PROCESSED_PATH, 'w') as f:
            json.dump(nse_eq_instruments, f, indent=4)

        logger.info(f"Successfully saved {len(nse_eq_instruments)} NSE_EQ instruments to {NSE_CSV_PROCESSED_PATH}")

        # Update in-memory cache
        global _instruments_cache
        _instruments_cache["NSE_EQ"] = nse_eq_instruments
        _instruments_cache["last_updated"] = datetime.now().isoformat()
        return True

    except requests.exceptions.RequestException as e:
        logger.error(f"Error downloading instruments from {NSE_CSV_URL}: {e}")
    except gzip.BadGzipFile:
        logger.error(f"Failed to decompress the downloaded file from {NSE_CSV_URL}. It might not be a valid Gzip file.")
    except csv.Error as e:
        logger.error(f"Error reading or parsing CSV data: {e}")
    except IOError as e:
        logger.error(f"Error writing processed instruments to {NSE_CSV_PROCESSED_PATH}: {e}")
    except Exception as e:
        logger.error(f"An unexpected error occurred during instrument processing: {e}", exc_info=True)
    return False

def get_auth_token_from_code(auth_code):
    """
    Exchange authorization code for access token

    Args:
        auth_code (str): The authorization code from OAuth callback

    Returns:
        str: The access token or None if failed
    """
    if not UPSTOX_API_KEY or not UPSTOX_API_SECRET or not UPSTOX_REDIRECT_URI:
        logger.error("Upstox API key, secret or redirect URI not configured")
        return None

    try:
        import requests
        token_url = "https://api.upstox.com/v2/login/authorization/token"

        # Prepare the data for token request
        data = {
            'code': auth_code,
            'client_id': UPSTOX_API_KEY,
            'client_secret': UPSTOX_API_SECRET,
            'redirect_uri': UPSTOX_REDIRECT_URI,
            'grant_type': 'authorization_code'
        }

        # Make the request to get the access token
        response = requests.post(token_url, data=data)
        if response.status_code == 200:
            token_data = response.json()
            if 'access_token' in token_data:
                # Save the token for future use
                token_manager.save_token(token_data['access_token'], int(token_data.get('expires_in', 86400)))
                logger.info("Upstox API V3: Access token obtained successfully from auth code")
                return token_data['access_token']
            else:
                logger.error(f"Upstox API V3: Invalid response format: {token_data}")
                return None
        else:
            logger.error(f"Upstox API V3: Failed to get access token from auth code, status code: {response.status_code}, response: {response.text}")
            return None
    except Exception as e:
        logger.error(f"Error getting Upstox access token from auth code: {e}")
        return None

def get_configuration():
    """
    Create and return an Upstox API configuration object
    """
    token = token_manager.get_token()
    if not token:
        return None

    configuration = Configuration()
    configuration.access_token = token
    return configuration

def get_configuration_api_client():
    """
    Create and return an Upstox API client instance.
    """
    token = token_manager.get_token()
    if not token:
        logger.error("Access token not available for Upstox API configuration.")
        return None

    config_obj = Configuration()
    config_obj.access_token = token
    api_client = upstox_client.ApiClient(configuration=config_obj)
    return api_client

def get_market_quote_api():
    """
    Get an instance of the MarketQuoteApi
    """
    config = get_configuration()
    if not config:
        return None
    return MarketQuoteApi(configuration=config)

def get_market_quote_v3_api():
    """
    Get an instance of the MarketQuoteV3Api
    """
    # Create an ApiClient instance instead of just a configuration
    api_client = get_configuration_api_client()
    if not api_client:
        return None
    # Initialize MarketQuoteV3Api with the api_client instance
    return MarketQuoteV3Api(api_client=api_client)

def get_history_v3_api():
    """
    Get an instance of the HistoryV3Api
    """
    # Create an ApiClient instance instead of just a configuration
    api_client = get_configuration_api_client()
    if not api_client:
        return None
    # Initialize HistoryV3Api with the api_client instance
    return HistoryV3Api(api_client=api_client)

def get_login_api():
    """
    Get an instance of the LoginApi for authentication flow
    """
    config = Configuration()  # No token needed for login
    if not config:
        return None
    return LoginApi(configuration=config)

def get_upstox_login_url():
    """
    Generate a login URL for Upstox authentication
    """
    try:
        login_api = get_login_api()
        response = login_api.login(
            api_version="3.0",
            redirect_uri=UPSTOX_REDIRECT_URI,
            api_key=UPSTOX_API_KEY,
            response_type="code",
            client_id=UPSTOX_API_KEY,
            scope="",
            state=""
        )
        return response.login_url
    except ApiException as e:
        logger.error(f"Exception when calling LoginApi->login: {e}")
        return None
    except Exception as e:
        logger.error(f"Error generating Upstox login URL: {str(e)}")
        return None

def get_market_data_feed_authorize_url(api_client_instance):
    """
    Gets the market data feed authorize URL using an ApiClient instance.
    """
    if not api_client_instance:
        logger.error("ApiClient instance is required for get_market_data_feed_authorize_url")
        return None
    try:
        ws_api = WebsocketApi(api_client_instance)
        response = ws_api.get_market_data_feed_authorize_v3()
        logger.info("Market data feed authorize URL obtained successfully.")
        return response.data.authorized_redirect_uri
    except ApiException as e:
        logger.error(f"ApiException when calling WebsocketApi->get_market_data_feed_authorize: {e}")
        if e.body:
            logger.error(f"Error body: {e.body}")
        return None
    except Exception as e:
        logger.error(f"Error getting market data feed authorize URL: {e}")
        return None

async def connect_and_stream_market_data(feed_url, instrument_keys, on_message_callback, shutdown_threading_event: threading.Event): # Modified signature
    """
    Connects to the Upstox market data WebSocket and streams data.
    Gracefully shuts down if shutdown_threading_event is set.
    """
    if not MarketDataFeed_pb2:
        logger.error("MarketDataFeed_pb2 module not loaded. Cannot stream market data.")
        return

    try:
        logger.info(f"Attempting to connect to WebSocket: {feed_url}")
        # Increased open_timeout to allow more time for connection establishment
        async with websockets.connect(feed_url, ping_interval=30, ping_timeout=10, open_timeout=20) as websocket:
            logger.info(f"Successfully connected to Upstox Market Data WebSocket: {feed_url}")

            sub_request = {
                "guid": "pyalgo-guid-" + str(time.time()),
                "method": "sub",
                "data": {
                    "instrumentKeys": instrument_keys
                }
            }
            await websocket.send(json.dumps(sub_request))
            logger.info(f"Sent subscription request for instruments: {instrument_keys}")

            while not shutdown_threading_event.is_set():
                try:
                    # Wait for a message with a timeout, so we can check the shutdown event
                    message = await asyncio.wait_for(websocket.recv(), timeout=1.0)
                    feed_response = MarketDataFeed_pb2.FeedResponse()
                    feed_response.ParseFromString(message)

                    if on_message_callback:
                        on_message_callback(feed_response)

                except asyncio.TimeoutError:
                    # Timeout occurred, loop again to check shutdown_event
                    continue
                except websockets.exceptions.ConnectionClosedOK:
                    logger.info("WebSocket connection closed gracefully by server (OK).")
                    break
                except websockets.exceptions.ConnectionClosedError as e:
                    logger.error(f"WebSocket connection closed with error by server: {e}")
                    break
                except websockets.exceptions.ConnectionClosed as e: # Catch any other ConnectionClosed variations
                    logger.error(f"WebSocket connection closed unexpectedly: {e}")
                    break
                except Exception as e: # Catch other potential errors during recv/parse
                    logger.error(f"Error during WebSocket recv/parse: {e}", exc_info=True)
                    break # Break on other errors to prevent tight loops on persistent issues

            if shutdown_threading_event.is_set():
                logger.info("Shutdown event received, WebSocket connection loop terminated.")

    except websockets.exceptions.InvalidStatusCode as e:
        logger.error(f"WebSocket connection failed: Invalid status code {e.status_code} from {feed_url}. Headers: {e.headers}")
    except websockets.exceptions.WebSocketException as e: # Generic websocket connection exception
        logger.error(f"WebSocket connection/protocol exception for {feed_url}: {e}", exc_info=True)
    except ConnectionRefusedError:
        logger.error(f"Connection refused for WebSocket: {feed_url}")
    except asyncio.TimeoutError: # Timeout during initial connection
        logger.error(f"Timeout establishing WebSocket connection to {feed_url}")
    except Exception as e:
        logger.error(f"An unexpected error occurred in WebSocket connection/streaming for {feed_url}: {e}", exc_info=True)
    finally:
        logger.info(f"WebSocket function connect_and_stream_market_data for {feed_url} is concluding.")


def get_historical_data(instrument_key, interval="1day", from_date=None, to_date=None, exchange="NSE_EQ"):
    """
    Get historical OHLC candle data from Upstox API

    Args:
        instrument_key (str): Instrument key in format like "NSE_EQ|INE002A01018"
        interval (str): Time interval such as "1minute", "5minute", "1day", etc.
        from_date (str): Start date in format YYYY-MM-DD
        to_date (str): End date in format YYYY-MM-DD
        exchange (str): Exchange code, default is NSE_EQ

    Returns:
        list: List of OHLC candles or None if error
    """
    try:
        api_client = get_configuration_api_client()
        if not api_client:
            logger.error("Failed to get API client for historical data.")
            return None

        history_api = upstox_client.HistoryV3Api(api_client)

        # Map interval to the format required by the Upstox API
        interval_mapping = {
            "1minute": {"unit": "minutes", "interval": 1},
            "3minute": {"unit": "minutes", "interval": 3},
            "5minute": {"unit": "minutes", "interval": 5},
            "15minute": {"unit": "minutes", "interval": 15},
            "30minute": {"unit": "minutes", "interval": 30},
            "1hour": {"unit": "hours", "interval": 1},
            "1day": {"unit": "days", "interval": 1},
            "1week": {"unit": "weeks", "interval": 1},
            "1month": {"unit": "months", "interval": 1}
        }

        # Get the unit and interval from the mapping
        mapped_params = interval_mapping.get(interval)
        if not mapped_params:
            logger.error(f"Invalid interval format for historical data: {interval}")
            return None

        unit = mapped_params["unit"]
        interval_value = mapped_params["interval"]

        logger.info(f"Fetching historical data for {instrument_key} with interval {interval_value} {unit}")
        # Default to last 30 days if no dates provided
        if not to_date:
            to_date = datetime.now().strftime("%Y-%m-%d")
        if not from_date:
            from_date = (datetime.now() - timedelta(days=60)).strftime("%Y-%m-%d")
        # API call to fetch historical data
        response = history_api.get_historical_candle_data(
            instrument_key=instrument_key,
            unit=unit,
            interval=interval_value,
            to_date=to_date
            # from_date parameter removed as it's not supported by the API
        )

        # Process the response data
        if response and hasattr(response, 'data') and hasattr(response.data, 'candles'):
            logger.info(f"Successfully retrieved historical data for {instrument_key}, got {len(response.data.candles)} candles")
            return response.data.candles
        else:
            logger.warning(f"No candle data in response for {instrument_key}")
            return None

    except AttributeError as e:
        logger.error(f"Method not found in HistoryV3Api: {e}")
        # Add detailed debug information
        logger.info(f"Available methods in HistoryV3Api: {[m for m in dir(history_api) if not m.startswith('_')]}")
        return None
    except ApiException as e:
        logger.error(f"API Exception when fetching historical data: {e}")
        if hasattr(e, 'body') and e.body:
            logger.error(f"Error body: {e.body}")
            # Try to parse the error for better debugging
            try:
                import json
                error_json = json.loads(e.body)
                logger.error(f"Parsed error: {json.dumps(error_json, indent=2)}")
            except:
                pass
        return None
    except Exception as e:
        logger.error(f"Error fetching historical data from Upstox for {instrument_key}: {e}")
        return None
def get_auth_code_from_url(redirect_url):
    """
    Extract the authorization code from the redirect URL
    For use with the redirect callback
    """
    try:
        import urllib.parse
        parsed_url = urllib.parse.urlparse(redirect_url)
        query_params = urllib.parse.parse_qs(parsed_url.query)

        if 'code' in query_params:
            return query_params['code'][0]
        return None
    except Exception as e:
        logger.error(f"Error extracting auth code from URL: {str(e)}")
        return None

def is_cache_stale(cache_file):
    """
    Check if the cache file is stale (older than 1 day)

    Args:
        cache_file (str): Path to the cache file

    Returns:
        bool: True if the file doesn't exist or is older than 1 day
    """
    try:
        if not os.path.exists(cache_file):
            logger.info(f"Cache file {cache_file} does not exist.")
            return True

        file_modified_time = datetime.fromtimestamp(os.path.getmtime(cache_file))
        current_time = datetime.now()

        # Calculate time difference in hours
        time_difference = (current_time - file_modified_time).total_seconds() / 3600

        # If cache is older than 24 hours (1 day), consider it stale
        is_stale = time_difference > 24
        if is_stale:
            logger.info(f"Cache file {cache_file} is stale, last updated {time_difference:.1f} hours ago.")

        return is_stale
    except Exception as e:
        logger.error(f"Error checking cache staleness for {cache_file}: {str(e)}")
        # If there's an error checking, consider the cache stale
        return True


def get_instruments_cache(exchange="NSE_EQ"):
    """
    Get instruments cache for the specified exchange.
    Loads from processed JSON file if available. If not, attempts to refresh it.
    Refreshes cache automatically if it's older than 1 day.

    Args:
        exchange (str): Exchange code, default is NSE_EQ (NSE Equity)

    Returns:
        list: List of instruments for the specified exchange
    """
    global _instruments_cache

    # Check if cache is already loaded in memory
    if _instruments_cache.get(exchange) is not None:
        cache_timestamp = _instruments_cache.get("last_updated")
        if cache_timestamp:
            try:
                # Check if in-memory cache is fresh (less than 1 day old)
                cache_time = datetime.fromisoformat(cache_timestamp)
                current_time = datetime.now()
                cache_age_hours = (current_time - cache_time).total_seconds() / 3600

                if cache_age_hours < 24:  # Less than 1 day old
                    return _instruments_cache[exchange]
                else:
                    logger.info(f"In-memory instrument cache is {cache_age_hours:.1f} hours old, refreshing...")
            except Exception as e:
                logger.warning(f"Error checking in-memory cache age: {e}")
                # Continue to refresh cache

    # Determine the cache file path
    cache_file_to_check = None
    if exchange == "NSE_EQ":
        cache_file_to_check = NSE_CSV_PROCESSED_PATH
    else:
        logger.warning(f"Instruments cache not implemented for exchange: {exchange}")
        return []

    # Check if file cache is stale
    cache_is_stale = is_cache_stale(cache_file_to_check)

    # If cache is stale, refresh it
    if cache_is_stale and exchange == "NSE_EQ":
        logger.info(f"Refreshing stale instrument cache for {exchange}...")
        if refresh_and_filter_nse_instruments():
            logger.info(f"Successfully refreshed instruments for {exchange}.")
            return _instruments_cache[exchange]
        else:
            logger.error(f"Failed to refresh instruments for {exchange}. Attempting to load existing cache.")

    # Try to load from file if available
    try:
        if os.path.exists(cache_file_to_check):
            with open(cache_file_to_check, 'r') as f:
                instruments = json.load(f)

            # Store in memory cache
            _instruments_cache[exchange] = instruments
            _instruments_cache["last_updated"] = datetime.now().isoformat()

            logger.info(f"Loaded {len(instruments)} instruments for {exchange} from cache file: {cache_file_to_check}")
            return instruments
        else:
            logger.warning(f"Instruments cache file not found: {cache_file_to_check}. Attempting to refresh.")
            # Attempt to refresh/create the cache file
            if exchange == "NSE_EQ":
                if refresh_and_filter_nse_instruments():
                    logger.info(f"Successfully refreshed and loaded instruments for {exchange}.")
                    # The refresh function already updates _instruments_cache
                    return _instruments_cache[exchange]
                else:
                    logger.error(f"Failed to refresh instruments for {exchange} after cache file was not found.")
                    return []
            else:
                # Should not happen if we returned earlier for non-NSE_EQ
                return []

    except json.JSONDecodeError as e:
        logger.error(f"Error decoding JSON from instruments cache file {cache_file_to_check}: {e}. Attempting to refresh.")
        if exchange == "NSE_EQ":
            if refresh_and_filter_nse_instruments():
                logger.info(f"Successfully refreshed and loaded instruments for {exchange} after JSON error.")
                return _instruments_cache[exchange]
            else:
                logger.error(f"Failed to refresh instruments for {exchange} after JSON error.")
                return []
        return [] # Should not happen
    except Exception as e:
        logger.error(f"Error loading instruments cache for {exchange} from {cache_file_to_check}: {str(e)}")
        return []

def search_instruments(query, exchange="NSE_EQ"):
    """
    Search for instruments based on a query string using Upstox OHLC V3 API

    Args:
        query (str): Search query string (tradingsymbol or name)
        exchange (str): Exchange code, default is NSE_EQ (NSE Equity)

    Returns:
        list: List of matching instruments
    """
    try:
        # Get the access token for authorization
        token = token_manager.get_token()
        if not token:
            logger.error("Failed to get access token for instrument search")
            return []

        # Get processed instruments cache
        instruments = get_instruments_cache(exchange)
        if not instruments:
            logger.error(f"No instruments available for exchange {exchange}")
            return []

        # Perform a case-insensitive search on both tradingsymbol and name
        query = query.upper()
        results = []

        for inst in instruments:
            # Check if the query matches the tradingsymbol or name
            tradingsymbol = inst.get('tradingsymbol', '').upper()
            name = inst.get('name', '').upper()

            if query in tradingsymbol or query in name:
                # Ensure the instrument has tradingsymbol field for consistency
                if 'tradingsymbol' not in inst:
                    logger.warning(f"Instrument missing tradingsymbol field: {inst}")
                    continue

                results.append(inst)

                # Limit results to a reasonable number
                if len(results) >= 20:
                    break

        return results
    except Exception as e:
        logger.error(f"Error searching instruments: {str(e)}")
        return []
def search_symbols(api_client, query, exchange="NSE_EQ"):
    """
    Search for symbols using the API client

    Args:
        api_client: Configured Upstox API client
        query (str): Search query string (symbol or name)
        exchange (str): Exchange code, default is NSE_EQ (NSE Equity)

    Returns:
        list: List of matching symbols with formatted data for frontend
    """
    try:
        # First try to search using existing instruments cache
        results = search_instruments(query, exchange)

        # Log the raw search results for debugging
        logger.info(f"Found {len(results)} raw results for query '{query}'")
        if len(results) > 0:
            logger.info(f"Sample result fields: {list(results[0].keys())}")

        # Format the results for frontend display
        formatted_results = []

        for inst in results:
            # Use tradingsymbol as the primary identifier
            tradingsymbol = inst.get('tradingsymbol', '')
            name = inst.get('name', '')

            # Get instrument_key or construct it if missing
            instrument_key = inst.get('instrument_key', '')

            # Check the exchange format - it could be either 'NSE_EQ' or just 'NSE'
            inst_exchange = inst.get('exchange', '')

            # Include the result if we have a tradingsymbol and either:
            # 1. The exchange matches exactly, or
            # 2. The exchange is part of the expected exchange (e.g., 'NSE' is in 'NSE_EQ')
            if tradingsymbol and (
                inst_exchange == exchange or
                exchange.startswith(inst_exchange) or
                inst_exchange.startswith(exchange.split('_')[0])
            ):
                formatted_results.append({
                    "symbol": tradingsymbol,  # Using tradingsymbol for the symbol field for consistency with frontend
                    "tradingsymbol": tradingsymbol,
                    "name": name,
                    "instrument_key": instrument_key,
                    "exchange": exchange  # Use the requested exchange for consistency
                })

        logger.info(f"Returning {len(formatted_results)} formatted symbols for query '{query}'")
        return formatted_results
    except Exception as e:
        logger.error(f"Error in search_symbols: {str(e)}")
        return []

def merge_historical_and_intraday_data(historical_data, intraday_data, interval):
    """
    Merge historical OHLC data with intraday data for seamless chart display

    Args:
        historical_data (list): List of OHLC candles from get_historical_data
        intraday_data (dict or list): Intraday data can be either:
                                      - List of OHLC candles from get_intra_day_candle_data
                                      - Dict with live market data
        interval (str): The interval of the historical data (e.g., "1day", "1minute")

    Returns:
        list: Merged data with intraday points appended/merged, with no duplicates
    """
    if historical_data is None or not historical_data:
        logger.warning("No historical data to merge")
        return []

    if intraday_data is None:
        logger.warning("No intraday data available to merge, returning historical data only")
        return historical_data

    # Use a dictionary to track candles by timestamp to avoid duplicates
    # Intraday data should take precedence over historical data when timestamps match
    candle_dict = {}
    # First add all historical candles to the dictionary
    for candle in historical_data:
        timestamp = candle[0]
        candle_dict[timestamp] = candle

    try:
        # Check if intraday_data is a list of candles (from get_intra_day_candle_data)
        if isinstance(intraday_data, list):
            logger.info(f"Merging historical data with {len(intraday_data)} intraday candles")

            # Add or update with intraday candles (will override historical if timestamp matches)
            for candle in intraday_data:
                timestamp = candle[0]
                candle_dict[timestamp] = candle

            # Convert back to a sorted list
            merged_data = list(candle_dict.values())
            merged_data.sort(key=lambda x: x[0])

            logger.info(f"Merged data has {len(merged_data)} candles after removing duplicates")
            return merged_data

        # Handle dict type intraday data (live market data)
        else:
            # Extract necessary data from intraday data dictionary
            ltp = intraday_data.get('ltp')
            if not ltp:
                logger.warning("Intraday data missing LTP, cannot create current candle")
                # Convert dictionary back to sorted list and return
                merged_data = list(candle_dict.values())
                merged_data.sort(key=lambda x: x[0])
                return merged_data

            # Get the timestamp for the current time
            current_time = datetime.now()

            # Format based on interval
            if interval == '1day':
                # Set time to beginning of the day for daily candle
                date_str = current_time.strftime("%Y-%m-%dT00:00:00+05:30")
            elif '1minute' in interval or '5minute' in interval or '15minute' in interval or '30minute' in interval:
                # Set time to current minute for minute-based candles
                # Round down to the nearest interval
                interval_minutes = int(interval.replace('minute', ''))
                minute_rounded = (current_time.minute // interval_minutes) * interval_minutes
                date_str = current_time.strftime(f"%Y-%m-%dT{current_time.hour:02d}:{minute_rounded:02d}:00+05:30")
            elif '1hour' in interval:
                # Set time to current hour for hourly candle
                date_str = current_time.strftime("%Y-%m-%dT%H:00:00+05:30")
            else:
                # Default format for other intervals
                date_str = current_time.strftime("%Y-%m-%dT%H:%M:%S+05:30")

            # Check if we already have a candle for this timestamp
            if date_str in candle_dict:
                # Update the existing candle with the current price
                existing_candle = candle_dict[date_str]

                # Keep the open price from the existing candle
                open_price = existing_candle[1]

                # Update high price if current price is higher
                high_price = max(existing_candle[2], ltp)

                # Update low price if current price is lower
                low_price = min(existing_candle[3], ltp)

                # Set close price to the current price
                close_price = ltp

                # Volume may be present in index 5
                volume = existing_candle[5] if len(existing_candle) > 5 else 0

                # Update the candle
                candle_dict[date_str] = [date_str, open_price, high_price, low_price, close_price, volume]
            else:
                # Add a new candle for the current time period
                logger.info(f"Adding new candle at {date_str} with price {ltp}")

                # For a new candle, set OHLC to the current price
                new_candle = [date_str, ltp, ltp, ltp, ltp, 0]
                candle_dict[date_str] = new_candle

            # Convert dictionary back to sorted list
            merged_data = list(candle_dict.values())
            merged_data.sort(key=lambda x: x[0])
            return merged_data

    except Exception as e:
        logger.error(f"Error merging historical and intraday data: {e}", exc_info=True)

        # In case of error, convert whatever we have in the dictionary to a list
        merged_data = list(candle_dict.values())
        merged_data.sort(key=lambda x: x[0])
        return merged_data

def get_intra_day_candle_data(instrument_key, interval="5minute", exchange="NSE_EQ"):
    """
    Get intraday candle data for an instrument from Upstox V3 API

    Args:
        instrument_key (str): Instrument key in format like "NSE_EQ|INE002A01018"
        interval (str): Candle interval (e.g., "1minute", "5minute", "15minute", "30minute", "1hour")
        exchange (str): Exchange code, default is NSE_EQ (NSE Equity)

    Returns:
        list: List of candles with timestamp and OHLCV values or None if an error occurs
    """
    # Daily intervals like 1day, 1week, 1month are not supported for intraday data
    if interval in ["1day", "1week", "1month"]:
        logger.info(f"Intraday data not available for interval {interval}. Use historical data instead.")
        return None

    history_api = get_history_v3_api()
    if not history_api:
        logger.error("Failed to create HistoryV3Api instance for intraday candle data")
        return None

    # Map interval to the format required by the Upstox API
    interval_mapping = {
        "1minute": {"unit": "minutes", "interval": 1},
        "3minute": {"unit": "minutes", "interval": 3},
        "5minute": {"unit": "minutes", "interval": 5},
        "15minute": {"unit": "minutes", "interval": 15},
        "30minute": {"unit": "minutes", "interval": 30},
        "1hour": {"unit": "hours", "interval": 1}
    }

    # Get the unit and interval from the mapping
    mapped_params = interval_mapping.get(interval)
    if not mapped_params:
        logger.error(f"Invalid interval format for intraday candle data: {interval}")
        return None

    unit = mapped_params["unit"]
    interval_value = mapped_params["interval"]

    try:
        logger.info(f"Fetching intraday candle data for {instrument_key} with unit={unit}, interval={interval_value}")

        # Call the API to get intraday candle data
        response = history_api.get_intra_day_candle_data(
            instrument_key=instrument_key,
            unit=unit,
            interval=interval_value
        )
        # Process the response data
        if response and hasattr(response, 'data') and hasattr(response.data, 'candles'):
            candles_data = response.data.candles
            logger.info(f"Successfully retrieved intraday candle data for {instrument_key}, got {len(candles_data)} candles")

            # Process and format the candle data to match the expected format
            formatted_candles = []
            for candle in candles_data:
                # Each candle should be a list with [timestamp, open, high, low, close, volume, oi]
                # The timestamp format should be "YYYY-MM-DDThh:mm:ss+05:30"
                formatted_candle = [
                    candle[0],           # timestamp
                    float(candle[1]),    # open
                    float(candle[2]),    # high
                    float(candle[3]),    # low
                    float(candle[4]),    # close
                    int(candle[5]),      # volume
                    0                    # oi (open interest) - defaulting to 0 if not available
                ]
                formatted_candles.append(formatted_candle)

            return formatted_candles
        else:
            logger.warning(f"No intraday candle data in response for {instrument_key}")
            return None

    except ApiException as e:
        logger.error(f"API Exception when fetching intraday candle data: {e}")
        if hasattr(e, 'body') and e.body:
            logger.error(f"Error body: {e.body}")
        return None
    except Exception as e:
        logger.error(f"Error fetching intraday candle data for {instrument_key}: {e}", exc_info=True)
        return None
def extract_ltpc_from_feed(feed_response):
    """
    Extract LTPC (Last Traded Price & Change) data from the market data feed response

    Args:
        feed_response: FeedResponse from the market data WebSocket

    Returns:
        dict: Dictionary with instrument_key as key and LTPC data as value
    """
    if not feed_response or not hasattr(feed_response, 'feeds'):
        return {}

    ltpc_data = {}

    try:
        for instrument_key, feed_data in feed_response.feeds.items():
            if feed_data.ff.marketFF.ltpc:
                ltpc = feed_data.ff.marketFF.ltpc
                ltpc_data[instrument_key] = {
                    "ltp": ltpc.ltp,                     # Last traded price
                    "change": ltpc.ch,                   # Change from previous close
                    "percentage_change": ltpc.chp,       # Change percentage
                    "close_price": ltpc.cp,              # Close price (previous day)
                    "last_trade_time": ltpc.ltt,         # Last trade time (timestamp)
                    "volume": ltpc.v if hasattr(ltpc, 'v') else None,  # Volume (if available)
                    "atp": ltpc.atp if hasattr(ltpc, 'atp') else None  # Average traded price (if available)
                }

        if ltpc_data:
            logger.info(f"Extracted LTPC data for {len(ltpc_data)} instruments from market data feed")
        return ltpc_data

    except Exception as e:
        logger.error(f"Error extracting LTPC data from market feed: {e}", exc_info=True)
        return {}

def get_full_market_quote(symbols=None, instrument_keys=None, exchange="NSE_EQ"):
    """
    Get full market quote data for given symbols/instrument keys from Upstox API

    Args:
        symbols (list): List of symbol strings (optional)
        instrument_keys (list): List of instrument keys (optional)
        exchange (str): Exchange code, default is NSE_EQ

    Returns:
        dict: Dictionary with instrument_key as key and full market data as value
    """
    market_quote_api = get_market_quote_v3_api()
    if not market_quote_api:
        logger.error("Failed to create MarketQuoteV3Api instance for full market quote")
        return None

    try:
        # If symbols are provided but not instrument_keys, convert symbols to instrument_keys
        if symbols and not instrument_keys:
            instrument_keys = []
            for symbol in symbols:
                instrument_keys.append(f"{exchange}|{symbol}")

        # If no instrument_keys are provided, return empty result
        if not instrument_keys:
            logger.warning("No symbols or instrument_keys provided for get_full_market_quote")
            return {}

        logger.info(f"Fetching full market quote for instrument keys: {instrument_keys}")

        # Make API call to get full market quote
        # According to the documentation, instrument_key can be a list
        response = market_quote_api.get_full_market_quote(
            instrument_key=instrument_keys
        )

        # Process response
        if response and hasattr(response, 'data'):
            result = response.data
            logger.info(f"Successfully fetched full market quote for {len(result)} instruments")

            # Process the data to ensure consistent format for frontend use
            processed_data = {}
            for key, quote in result.items():
                # Extract relevant data fields based on the API documentation
                processed_data[key] = {
                    "instrument_key": key,
                    "last_price": quote.get("last_price"),
                    "ohlc": quote.get("ohlc", {}),
                    "depth": {
                        "buy": quote.get("depth", {}).get("buy", []),
                        "sell": quote.get("depth", {}).get("sell", [])
                    },
                    "timestamp": quote.get("timestamp"),
                    "volume": quote.get("volume"),
                    "oi": quote.get("oi"),  # Open Interest
                    "oi_day_high": quote.get("oi_day_high"),
                    "oi_day_low": quote.get("oi_day_low"),
                    "total_buy_qty": quote.get("total_buy_quantity"),
                    "total_sell_qty": quote.get("total_sell_quantity"),
                    "lower_circuit": quote.get("lower_circuit_limit"),
                    "upper_circuit": quote.get("upper_circuit_limit"),
                    "atp": quote.get("atp"),  # Average Traded Price
                    "change": quote.get("change"),
                    "change_percent": quote.get("percentage_change")
                }

            return processed_data
        else:
            logger.warning("No data in full market quote response")
            return {}

    except ApiException as e:
        logger.error(f"API Exception when fetching full market quote: {e}")
        if hasattr(e, 'body') and e.body:
            logger.error(f"Error body: {e.body}")
        return {}
    except Exception as e:
        logger.error(f"Error fetching full market quote: {e}", exc_info=True)
        return {}
def get_full_market_quote_v2(symbols=None, instrument_keys=None, exchange="NSE_EQ"):
    """
    Get full market quote data using direct HTTP request to V2 API endpoint

    Args:
        symbols (list): List of symbol strings (optional)
        instrument_keys (list): List of instrument keys (optional)
        exchange (str): Exchange code, default is NSE_EQ

    Returns:
        dict: Dictionary with instrument_key as key and full market data as value
    """
    try:
        # Get authentication token
        token = token_manager.get_token()
        if not token:
            logger.error("Failed to get access token for full market quote V2")
            return None

        # If symbols are provided but not instrument_keys, convert symbols to instrument_keys
        if symbols and not instrument_keys:
            instrument_keys = []

            # Get instruments cache to lookup proper instrument_keys
            instruments_cache = get_instruments_cache(exchange)
            if not instruments_cache:
                logger.error(f"Cannot convert symbols to instrument_keys: No instruments available for {exchange}")
                return {}

            for symbol in symbols:
                # Find the instrument with matching symbol/tradingsymbol
                instrument_found = False
                for instrument in instruments_cache:
                    # Check if this instrument matches our symbol (checking both fields)
                    if (instrument.get('tradingsymbol') == symbol or instrument.get('symbol') == symbol):
                        # Use the actual instrument_key from cache
                        if 'instrument_key' in instrument:
                            instrument_keys.append(instrument['instrument_key'])
                            instrument_found = True
                            break

                # If no matching instrument was found, fall back to simple concatenation
                if not instrument_found:
                    logger.warning(f"No instrument key found for symbol {symbol}, using fallback format")
                    instrument_keys.append(f"{exchange}|{symbol}")

        # If no instrument_keys are provided, return empty result
        if not instrument_keys:
            logger.warning("No symbols or instrument_keys provided for get_full_market_quote_v2")
            return {}

        logger.info(f"Fetching full market quote from V2 API for instrument keys: {instrument_keys}")

        # Build URL directly with instrument_keys, similar to test.py
        base_url = "https://api.upstox.com/v2/market-quote/quotes"
        instrument_keys_param = ",".join(instrument_keys)
        url = f"{base_url}?instrument_key={instrument_keys_param}"

        # Set up headers with authentication
        headers = {
            'Accept': 'application/json',
            'Authorization': f'Bearer {token}'
        }

        # Make the request with direct URL
        logger.info(f"Making request to URL: {url}")
        response = requests.get(url, headers=headers)
        response.raise_for_status()  # Raise exception for HTTP errors

        # Process response
        json_response = response.json()
        if 'data' in json_response:
            result = json_response['data']
            logger.info(f"Successfully fetched full market quote from V2 API for {len(result)} instruments")

            # Process the data to ensure consistent format for frontend use
            processed_data = {}

            # The result is a dictionary where keys are instrument_keys (in format "NSE_EQ:SYMBOL")
            for key, quote in result.items():
                # Extract instrument token from the quote data
                instrument_token = quote.get("instrument_token")
                if not instrument_token:
                    continue

                # Extract relevant data fields from V2 API response
                processed_data[instrument_token] = {
                    "instrument_key": instrument_token,
                    "last_price": quote.get("last_price"),
                    "ohlc": {
                        "open": quote.get("ohlc", {}).get("open"),
                        "high": quote.get("ohlc", {}).get("high"),
                        "low": quote.get("ohlc", {}).get("low"),
                        "close": quote.get("ohlc", {}).get("close")
                    },
                    "depth": {
                        "buy": quote.get("depth", {}).get("buy", []),
                        "sell": quote.get("depth", {}).get("sell", [])
                    },
                    "timestamp": quote.get("timestamp"),
                    "volume": quote.get("volume"),
                    "oi": quote.get("oi"),  # Open Interest
                    "oi_day_high": quote.get("oi_day_high"),
                    "oi_day_low": quote.get("oi_day_low"),
                    "total_buy_qty": quote.get("total_buy_quantity"),
                    "total_sell_qty": quote.get("total_sell_quantity"),
                    "lower_circuit": quote.get("lower_circuit_limit"),
                    "upper_circuit": quote.get("upper_circuit_limit"),
                    "atp": quote.get("atp"),  # Average Traded Price
                    "change": quote.get("change"),
                    "change_percent": quote.get("change_percent")
                }

            return processed_data
        else:
            logger.warning(f"No data in full market quote V2 response. Response: {json_response}")
            return {}

    except requests.exceptions.RequestException as e:
        logger.error(f"Request Exception when fetching full market quote from V2 API: {e}")
        if hasattr(e, 'response') and e.response:
            logger.error(f"Response status: {e.response.status_code}, content: {e.response.text}")
        return {}
    except Exception as e:
        logger.error(f"Error fetching full market quote from V2 API: {e}", exc_info=True)
        return {}
def get_instrument_key_from_cache(symbol):
    """
    Get the instrument_key from the instrument cache based on the tradingsymbol

    Args:
        symbol (str): The tradingsymbol to look up

    Returns:
        str: The instrument_key if found, None otherwise
    """
    try:
        # Get the instruments cache for NSE_EQ exchange
        exchange = "NSE_EQ"  # Using default exchange directly
        instruments = get_instruments_cache(exchange)
        if not instruments:
            logger.warning(f"No instruments available for exchange {exchange}")
            return None

        # Look for an exact match on tradingsymbol (case-insensitive)
        symbol_upper = symbol.upper()
        for inst in instruments:
            tradingsymbol = inst.get('tradingsymbol', '').upper()
            if tradingsymbol == symbol_upper:
                instrument_key = inst.get('instrument_key')
                if instrument_key:
                    logger.debug(f"Found instrument_key {instrument_key} for {symbol}")
                    return instrument_key

        # If no match found, check symbol field as fallback
        for inst in instruments:
            inst_symbol = inst.get('symbol', '').upper()
            if inst_symbol == symbol_upper:
                instrument_key = inst.get('instrument_key')
                if instrument_key:
                    logger.debug(f"Found instrument_key {instrument_key} for {symbol} (via symbol field)")
                    return instrument_key

        # If still no match, log a warning and return None
        logger.warning(f"No instrument_key found for symbol {symbol} in {exchange}")
        return None

    except Exception as e:
        logger.error(f"Error getting instrument_key from cache for {symbol}: {str(e)}")
        # Return None in case of error
        return None

def get_access_token():
    """
    Get the current access token from the token manager.

    Returns:
        str: The access token if available, None otherwise
    """
    try:
        token = token_manager.get_token()
        if token:
            logger.info("Successfully retrieved access token from token manager")
            return token
        else:
            logger.warning("No access token available in token manager")
            return None
    except Exception as e:
        logger.error(f"Error getting access token: {e}")
        return None
